{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70507ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "# 현재 작업 디렉토리의 절대 경로를 얻는다\n",
    "ROOT_DIR = os.path.abspath(os.curdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2137b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 불러오기 (train 데이터의 10% 비율로 test 데이터 생성)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9ab7593",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "\n",
    "# 비율 설정 10 % \n",
    "ratio = 0.1\n",
    "\n",
    "# 디렉토리 경로를 결합  \n",
    "src_root_dir = os.path.join(ROOT_DIR,'./dataset/cats_n_dogs_emotion/train/')\n",
    "dst_root_dir = os.path.join(ROOT_DIR,'./dataset/cats_n_dogs_emotion/test/')\n",
    "\n",
    "# src_root_dir 에 있는 파일과 디렉토리의 이름으로 이룩어진 리스트 반환 \n",
    "label_name_list = os.listdir(src_root_dir)\n",
    "\n",
    "\n",
    "# 반환된 리스트에서 요소를 하나씩 뽑아 dst_root_dir 경로와 결합 \n",
    "for label_name in label_name_list:\n",
    "    dst_label_name_dir = dst_root_dir + label_name\n",
    "\n",
    "# 해당 디렉토리가 존재하지 않는다면 해당경로에 새로운 디렉토리 생성  \n",
    "    if not os.path.exists(dst_label_name_dir):\n",
    "        os.mkdir(dst_label_name_dir)\n",
    "        \n",
    "\n",
    "# 해당 경로에 매칭되는 파일 목록 가져오기 \n",
    "# ratio 비율과 첫번째 변수의 길이를 곱하여 정수로 변환 \n",
    "# split_num 으로 요소 분해 하여 학습이미지중 일부를 테스트 이미지로 분리\n",
    "for label_name in label_name_list:\n",
    "    train_image_file_list = glob.glob(src_root_dir+label_name+'/*')\n",
    "    split_num = int(ratio*len(train_image_file_list))\n",
    "    test_image_file_list = train_image_file_list[0:split_num]\n",
    "\n",
    "# 테스트 이미지로 분리한 것들을 새로운 디렉토리로 move \n",
    "    for image_file in test_image_file_list:\n",
    "        shutil.move(image_file, dst_root_dir+label_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9077e8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기 (test 디렉토리 파일 -> test_image_files 디렉토리로 복사)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20169d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total [angry] image file nums => [149]\n",
      "total copy nums => 149\n",
      "total [happy] image file nums => [67]\n",
      "total copy nums => 67\n",
      "total [sad] image file nums => [99]\n",
      "total copy nums => 99\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import glob \n",
    "import shutil\n",
    "\n",
    "# 디렉토리 경로를 결합  \n",
    "src_root_dir = os.path.join(ROOT_DIR,'./dataset/cats_n_dogs_emotion/test/')\n",
    "dst_root_dir = os.path.join(ROOT_DIR,'./dataset/cats_n_dogs_emotion/test_image_files/')\n",
    "\n",
    "# 반환된 리스트에서 요소를 하나씩 뽑아 dst_root_dir 경로와 결합 \n",
    "label_name_list = os.listdir(src_root_dir)\n",
    "\n",
    "# 해당 경로에 매칭되는 파일 목록 가져오기\n",
    "# 해당 레이블의 이미지 파일수 출력 \n",
    "for label_name in label_name_list:\n",
    "    image_file_list = glob.glob(src_root_dir+label_name+'/*')\n",
    "    print('total [%s] image file nums => [%s]' % (label_name, len(image_file_list)))\n",
    "    \n",
    "    # 변수 초기화 \n",
    "    copy_nums = 0 \n",
    "    \n",
    "    #imgae_file 을 dst_root_dir 로 복사 \n",
    "    # 복사된 이미지 파일 갯수 출력\n",
    "    for image_file in image_file_list:\n",
    "        shutil.copy(image_file, dst_root_dir)\n",
    "        copy_nums = copy_nums + 1 \n",
    "        \n",
    "    print('total copy nums =>', copy_nums)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00e79ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageDataGenerator 정의 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e15a6f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 크기 변수에 저장\n",
    "IMG_WIDTH = 224 \n",
    "IMG_HEIGHT = 224 \n",
    "\n",
    "# 디렉토리 경로를 결합  \n",
    "train_dir = os.path.join(ROOT_DIR, './dataset/cats_n_dogs_emotion/train/')\n",
    "validation_dir = os.path.join(ROOT_DIR, './dataset/cats_n_dogs_emotion/train/')\n",
    "test_dir = os.path.join(ROOT_DIR,'./dataset/cats_n_dogs_emotion/test/') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b707ea2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# train 데이터로 부터 15% 비율로 validation data 생성\n",
    "# 이미지 데이터 전처리\n",
    "# rescale 이미지 데이터의 픽셀 값을 0과 1사이의 값으로 재조정\n",
    "# 신경망 모델의 학습을 더 잘 수행 할 수 있도록\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=20, width_shift_range=0.2,\n",
    "                                  height_shift_range=0.2, shear_range=0.2, zoom_range=0.2,\n",
    "                                  validation_split=0.15)\n",
    "# 이미지 데이터 전치리 및 데이터 생성에 사용  \n",
    "validation_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc38c8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 397 images belonging to 3 classes.\n",
      "Found 67 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# train_dir  : 학습 데이터가 있는 디렉토리 경로지정 \n",
    "# batch_size : 생성할 배치 사이즈 16\n",
    "# color_mode : 이미지 컬러 모드를 지정\n",
    "# class_mode : 클래스 모드 지정 sparse : 정수형 레이블 반환 \n",
    "# subset     : 이터의 하위 집합 지정 \n",
    "#target_size : 이미지의 타겟 크기를 지정\n",
    "# flow_from_directory : 데이터 생성기를 생성하고, 이미지를 로드하여 배치 단위로 반환\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, batch_size=16, color_mode='rgb',\n",
    "                                                   class_mode='sparse', subset='training',\n",
    "                                                   target_size=(IMG_WIDTH,IMG_HEIGHT))\n",
    "\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(validation_dir, batch_size=16, color_mode='rgb', \n",
    "                                                             class_mode='sparse', subset= 'validation',\n",
    "                                                             target_size=(IMG_WIDTH,IMG_HEIGHT))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "724cdd93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'angry': 0, 'happy': 1, 'sad': 2}\n"
     ]
    }
   ],
   "source": [
    "#해당 클래스 인덱스 확인\n",
    "print(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "058ec8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델구축 (Pre-Trained MobileNet + User-Defined Classfier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24aec1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet import MobileNet, preprocess_input, decode_predictions\n",
    "\n",
    "\n",
    "# MobileNet은 사전 훈련된 가중치를 사용하여 이미지 분류 및 특성 추출과 같은 작업에 사용되는 네트워크 아키텍처입니다.\n",
    "# weights : 사전 훈련된 ImageNet 데이터셋의 가중치를 사용하도록 설정하는 매개변수 \n",
    "# include_top=False : 네트워크의 상단에 있는 완전 연결 레이어를 포함하지 않도록 설정하는 매개변수입니다.\n",
    "# input_shape : 입력 이미지의 형태를 지정하는 매개변수, 이미지 채널수 3 \n",
    "base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(IMG_WIDTH, IMG_HEIGHT, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2bdee89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Activation, Flatten, Dropout\n",
    "#Sequential 모델 생성 \n",
    "model = Sequential()\n",
    " \n",
    "# MoblileNet 모델을 추가 \n",
    "model.add(base_model)\n",
    "\n",
    "# 2D 특성맵을 -> 1D 벡터로 변환 \n",
    "model.add(Flatten())\n",
    "\n",
    "# user-defined classifier\n",
    "# 사용자 정의 분류기 32개의 뉴런을 가진 완전 연결 레이어를 추가 \n",
    "# 활성화 함수로는 relu\n",
    "model.add(Dense(32, activation='relu'))\n",
    "# 25% 드롭아웃 적용하는 레이어 추가 과적합을 방지하기위해 임의로 일부 뉴런을 비활성화 \n",
    "model.add(Dropout(0.25))\n",
    "# 3개의 클래스에 대한 출력을 생성하는 완전연결 레이어 \n",
    "# 활성화 함수로는 softmax \n",
    "model.add(Dense(3, activation='softmax')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "13ee7939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenet_1.00_224 (Functio  (None, 7, 7, 1024)       3228864   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 50176)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                1605664   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,834,627\n",
      "Trainable params: 4,812,739\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from keras import optimizers\n",
    "\n",
    "# loss = 정수형 레이블을 인코딩 된 형태로 처리\n",
    "# Adam = 경사 하강법의 한 종류, 모델의 가중치 업데이트 \n",
    "# 2e-5 = 학습률 (엡데이트의 크기를 조절하는 매개변수) 2 * 10^(-5) => 0.00002 \n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer = tf.keras.optimizers.Adam(2e-5), metrics =['accuracy'])\n",
    "\n",
    "# 모델 구조 요약 출력 \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f21c1f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델에 학습 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "523f8cf6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 조기종료 구현 \u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# EarlyStopping:  지정된 기준에 따라 모델의 학습을 조기에 종료할 수 있는 콜백 함수 \u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# patience = 5\u001b[39;00m\n\u001b[0;32m      6\u001b[0m earlystopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m hist\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mfit(train_generator, validation_data\u001b[38;5;241m=\u001b[39mvalidation_generator, epochs\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, callbacks\u001b[38;5;241m=\u001b[39m[earlystopping])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# 조기종료 구현 \n",
    "# EarlyStopping:  지정된 기준에 따라 모델의 학습을 조기에 종료할 수 있는 콜백 함수 \n",
    "# patience = 5 :  조기종료 판단 기준, 검증 손실이 5번의 에포크 동안 개선되지 않으면 학습중지, 최상의 모델 저장 \n",
    "earlystopping = EarlyStopping(monitor = 'val_loss', patience=5)\n",
    "\n",
    "# fit 함수로 학습 진행 \n",
    "# 학습데이터, 검증데이터, 에포크 횟수, 조기종료 구현 함수 등을 포함\n",
    "hist=model.fit(train_generator, validation_data=validation_generator, epochs= 20, callbacks=[earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "51dc92e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 모델을 계속적으로 학습시킬수 없으니 HDF5 파일 형식의 Keras 모델을 지정한 경로에 저장 \n",
    "model.save('./savedata/emotion.h5')\n",
    "# 저장된 학습모델 불러오기 \n",
    "#h5_model=tf.keras.models.load_model('./savedata/emotion.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd93fb04",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ROOT_DIR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m label_dict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mangry\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhappy\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msad\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m2\u001b[39m}\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# 지정된 경로에 있는 모든 .jpg 확장자 파일들의 목록을 가져옴 \u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m test_image_files_list \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(\u001b[43mROOT_DIR\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./dataset/cats_n_dogs_emotion/test_image_files/*.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# 무작위로 파일들을 섞음\u001b[39;00m\n\u001b[0;32m     14\u001b[0m random\u001b[38;5;241m.\u001b[39mshuffle(test_image_files_list)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ROOT_DIR' is not defined"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os \n",
    "import numpy as np \n",
    "import cv2 \n",
    "import glob \n",
    "\n",
    "# 해당 레이블에 대응하는 정수 인데스를 매핑하는 딕셔너리를 생성\n",
    "label_dict = {'angry':0, 'happy':1, 'sad':2}\n",
    "\n",
    "# 지정된 경로에 있는 모든 .jpg 확장자 파일들의 목록을 가져옴 \n",
    "test_image_files_list = glob.glob(ROOT_DIR + './dataset/cats_n_dogs_emotion/test_image_files/*.jpg')\n",
    "\n",
    "# 무작위로 파일들을 섞음\n",
    "random.shuffle(test_image_files_list)\n",
    "\n",
    "# 16개의 파일 테스트할 예정\n",
    "test_num = 16\n",
    "test_image_files = test_image_files_list[:test_num] # 테스트 파일 이름은 정답. 숫자. jpg\n",
    "\n",
    "\n",
    "label_list = []\n",
    "\n",
    "# 이미지 파일의 경로에서 레이블 추출하여 변수에 담을것, 인덱스를 매핑하기 위해서 \n",
    "for i in range(len(test_image_files)):\n",
    "    print(test_image_files[i])\n",
    "    label = test_image_files[i].split('/')[-1].split('.')[0].strip()\n",
    "    label2 = label.split('\\\\')[1]\n",
    "    print(label1)            \n",
    "    #label = 'happy'\n",
    "    label_list.append(label_dict[label2])\n",
    "    \n",
    "src_image_list = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(test_image_files)):\n",
    "    # imread : 경로에 있는 테스트 이미지 파일을 컬러로 읽어옴 \n",
    "    src_img = cv2.imread(test_image_files[i], cv2.IMREAD_COLOR)\n",
    "    \n",
    "    # resize : 이이미지의 크기 조절 \n",
    "    src_img = cv2.resize(src_img, dsize=(IMG_WIDTH, IMG_HEIGHT))\n",
    "    \n",
    "    # cvtColor : BGR 채널 순서를 RGB 채널 순서로 변경 \n",
    "    src_img = cv2.cvtColor(src_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # 이미지를 0과 1사이의 값으로 정규화 \n",
    "    src_img = src_img / 255.0\n",
    "\n",
    "    # 전처리된 이미지를 list 에 추가 \n",
    "    src_image_list.append(src_img)\n",
    "    \n",
    "\n",
    "\n",
    "#4차원 텐서 변환 \n",
    "#배열로 변환함으로써 데이터를 효율적으로 다루고 다양한 배열 연산을 수행할 수 있음\n",
    "src_image_array = np.array(src_image_list)\n",
    "label_array = np.array(label_list) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a02198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16 개 테스트 이미지 파일에 대한 prediction 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063cab6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 모델로 테스트 이미지 예측 \n",
    "pred = h5_model.predict(src_image_list)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbfdca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 결과와 해당이미지를 시각화 하기위해 \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "\n",
    "class_names =['happy', 'sad', 'angry']\n",
    "\n",
    "# 출력할 그림의 크기를 설정 \n",
    "plt.figure(figsize=(12,12))\n",
    "\n",
    "# 예측 결과와 이미지를 하나씩 시각화\n",
    "for pos in range(len(pred)):\n",
    "    \n",
    "    # 서브 플롯이 생성될 행, 열의 갯수 나타냄, 1부터 시작하여 행우선으로 증가\n",
    "    plt.subplot(4,4,pos+1)\n",
    "    # 시각화 결과에서 축과 눈금 숨김\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # 정수형 레이블을 해당 문자열로 변환 \n",
    "    label_str = class_names[label_array[pos]]\n",
    "    # 예측 결과의 가장 높은값을 인덱스로 가져온후 해당 문자열로 변환 \n",
    "    pred_str = class_names[np.argmax(pred[pos])]\n",
    "    \n",
    "    # 제목 설정 \n",
    "    plt.title('label:' + label_str + '\\npred:' + pred_str)\n",
    "    \n",
    "    # 시각화 \n",
    "    plt.imshow(src_image_array[pos])\n",
    "# 배치     \n",
    "plt.tight_layout()\n",
    "# 출력\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c579d2a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b240665a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
